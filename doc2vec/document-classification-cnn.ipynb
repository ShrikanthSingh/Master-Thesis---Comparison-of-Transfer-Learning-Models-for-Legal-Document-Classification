{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "import keras_metrics\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "\n",
    "\n",
    "from keras import Sequential\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import Sequence\n",
    "from keras.initializers import Constant\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading of trained Doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('/content/drive/MyDrive/Thesis - Dataset and Transformations/doc2vec/Doc2Vec_500d_model/Doc2vec_500D.model') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the dataset - Augmented from the actual dataset (Without summarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_svd = pd.read_csv('/content/drive/MyDrive/Thesis - Dataset and Transformations/doc2vec/document_doc2vec_cnn_classification.csv')\n",
    "lsa_svd.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inferring the vectors for the documents from the trained document embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_vector(df):\n",
    "    '''\n",
    "    Function: Infer a vector for given post-bulk training document. Document should be a list of (word) tokens.\n",
    "    '''\n",
    "    inferred_vector = []\n",
    "    vector_label = []\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    \n",
    "    # infer_vector() requires its doc_words argument to be a list of tokens â€“ matching the same kind \n",
    "    # of tokenization that was used in training the model.\n",
    "    for idx, row in df.iterrows():\n",
    "        print('Inferring vectors for', idx)\n",
    "        inferred_vector.append(model.infer_vector(row['Summarized_content'].translate(table).split(), \n",
    "                                                  epochs = 40, alpha = 0.025))\n",
    "        vector_label.append(row['Labels']) \n",
    "    return inferred_vector, vector_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(hist_of_A, hist_of_B, title, xlabel, ylabel):\n",
    "    figure(num=None, figsize=(5, 4), dpi=350)\n",
    "    plt.plot(history.history[hist_of_A])\n",
    "    plt.plot(history.history[hist_of_B])\n",
    "    plt.title(title)\n",
    "    plt.xlim([0, 15])\n",
    "    plt.xticks(np.arange(0, 25, 5))\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.legend(['train', 'valid'], loc='upper right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatconmat(y_true,y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(15,12))\n",
    "    sns.heatmap(confusion_matrix(y_true,y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(y_true.unique()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_vector, vector_label = infer_vector(lsa_svd)\n",
    "inputs = np.array(inferred_vector)\n",
    "targets = np.array(vector_label)\n",
    "inputs = inputs.reshape((inputs.shape[0],inputs.shape[1],1))\n",
    "True_labels = list(dict.fromkeys(vector_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(inputs, targets, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining all the types of callbacks to be included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.95, patience=1, verbose=2,\n",
    "                                mode='auto', min_delta=0.05, cooldown=0, min_lr=0)\n",
    "\n",
    "filepath=r\"C:\\\\Users\\\\Shrikanth Singh\\\\Desktop\\\\Thesis-Note-to-Py\\\\bestofbest.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "EarlyStopping_call = EarlyStopping(monitor='val_acc', patience=5, mode='auto')\n",
    "\n",
    "callbacks_list = [call_reduce, checkpoint, EarlyStopping_call]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model definintion, K-fold cross validation, Model fitting and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "num_folds = 5\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "fold_no = 1\n",
    "for train, test in kfold.split(X_train_val, y_train_val):\n",
    "\n",
    "  # Define the model architecture\n",
    "    model_cnn = Sequential()\n",
    "\n",
    "    model_cnn.add(Conv1D(256, 3, activation='relu', padding='same', strides=1, \n",
    "                         kernel_regularizer=regularizers.l2(5e-4), input_shape=(500,1), \n",
    "                         use_bias=True, bias_initializer='TruncatedNormal', bias_regularizer=regularizers.l2(5e-4)))\n",
    "    model_cnn.add(MaxPooling1D(2))\n",
    "    model_cnn.add(Dropout(0.5))\n",
    "\n",
    "    model_cnn.add(Conv1D(256, 3, activation='relu', padding='same',strides=1, \n",
    "                         kernel_regularizer=regularizers.l2(5e-4), \n",
    "                         use_bias=True, bias_initializer='TruncatedNormal', bias_regularizer=regularizers.l2(5e-4)))\n",
    "    model_cnn.add(MaxPooling1D(2))\n",
    "    model_cnn.add(Dropout(0.5))\n",
    "\n",
    "    model_cnn.add(Flatten())\n",
    "    \n",
    "    model_cnn.add(Dense(200))\n",
    "    model_cnn.add(Dropout(0.5))\n",
    "    \n",
    "    model_cnn.add(Dense(len(True_labels), activation='softmax'))\n",
    "\n",
    "  # Compile the model\n",
    "    model_cnn.compile(loss='sparse_categorical_crossentropy',\n",
    "                      optimizer='rmsprop', \n",
    "                      metrics=['acc'])\n",
    "\n",
    "  # Generate a print\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "  # Fit data to model\n",
    "    \n",
    "    history = model_cnn.fit(X_train_val[train], y_train_val[train],\n",
    "              batch_size=16,\n",
    "              epochs=2,\n",
    "              verbose=1,\n",
    "              validation_split=0.2,\n",
    "              callbacks=callbacks_list)\n",
    "    \n",
    "    plot_graph(hist_of_A='acc', hist_of_B='val_acc', title='model accuracy', xlabel='epoch', ylabel='accuracy')\n",
    "    plot_graph(hist_of_A='loss', hist_of_B='val_loss', title='model loss', xlabel='epoch', ylabel='loss')\n",
    "    \n",
    "  # Generate generalization metrics\n",
    "    model_cnn.load_weights(r\"C:\\\\Users\\\\Shrikanth Singh\\\\Desktop\\\\Thesis-Note-to-Py\\\\bestofbest.hdf5\")\n",
    "    scores = model_cnn.evaluate(X_train_val[test], y_train_val[test], verbose=0)\n",
    "    print(f'Score for fold {fold_no}: {model_cnn.metrics_names[0]} of {scores[0]}; {model_cnn.metrics_names[1]} of {scores[1]*100}%')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "\n",
    "  # Increase fold number\n",
    "    fold_no = fold_no + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')  \n",
    "for i in range(0, len(acc_per_fold)):\n",
    "    print('------------------------------------------------------------------------') \n",
    "    print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "print('------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification performance on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model_cnn.predict_classes(X_test)\n",
    "print(classification_report(y_test,predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatconmat(pd.Series(y_test),predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
