{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import ast\n",
    "import nltk\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "import lexnlp.extract.en.acts\n",
    "import lexnlp.extract.en.dates\n",
    "import lexnlp.extract.en.courts\n",
    "import lexnlp.extract.en.trademarks\n",
    "import lexnlp.extract.en.regulations\n",
    "import lexnlp.extract.en.entities.nltk_re\n",
    "from lexnlp.extract.en.addresses import address_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actsData_Cleaning(x):\n",
    "    '''\n",
    "    Function - Minor cleaning of Acts data to remove incomplete tokens.\n",
    "    '''\n",
    "    remove_list = ['act', 'the act']\n",
    "    clean_x = list()\n",
    "    for each_x in x:\n",
    "        clean_x.append(\" \".join(each_x.lower().split()))\n",
    "    clean_x = list(filter(lambda i: i not in remove_list, clean_x))\n",
    "    return list(set(clean_x))\n",
    "\n",
    "def regData_Cleaning(x):\n",
    "    '''\n",
    "    Function - Minor cleaning of Regulations data to remove incomplete tokens.\n",
    "    '''\n",
    "    low_case_x = [i.lower() for i in x]\n",
    "    return list(set(low_case_x))\n",
    "\n",
    "def legal_data_extraction(path):\n",
    "    '''\n",
    "    Function: Captures the Acts and Regulations from the legal documents and creates a new column for each of them named\n",
    "    RegulationsData and ActsData respectively.\n",
    "    '''\n",
    "    raw_dataset = pd.read_csv(path)\n",
    "    \n",
    "    DocDetails = pd.DataFrame(columns=['RegulationsData',  'ActsData',])\n",
    "    for idx, row in raw_dataset.iterrows():\n",
    "        Acts = list()\n",
    "        clean_content = row['Case_document']\n",
    "        acts_ = lexnlp.extract.en.acts.get_act_list(clean_content)\n",
    "        for act in acts_:\n",
    "            Acts.append(re.sub(r'[^A-Za-z0-9 ]+', '', act.get('value')))\n",
    "        regulations_ = [re.sub('[\\W_]+', '', x[1]) for x in list(lexnlp.extract.en.regulations.get_regulations(clean_content))]\n",
    "        temp_doc_data = pd.DataFrame({'RegulationsData': [regulations_], 'ActsData':[Acts]}, index = [0])\n",
    "        DocDetails = DocDetails.append(temp_doc_data, ignore_index=True, sort=False)\n",
    "\n",
    "    raw_dataset['ActsData'] = pd.Series(DocDetails['ActsData'])\n",
    "    raw_dataset['RegulationsData'] = pd.Series(DocDetails['RegulationsData'])\n",
    "\n",
    "    raw_dataset['RegulationsData'] = list(raw_dataset['RegulationsData'].apply(lambda x: regData_Cleaning(x)))\n",
    "    raw_dataset['ActsData'] = list(raw_dataset['ActsData'].apply(lambda x: actsData_Cleaning(x)))\n",
    "    \n",
    "    raw_dataset.to_csv('Thesis - Dataset and Transformations/transform - post legal data extraction/raw_dataset_legal_entities.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':    \n",
    "    path = 'Thesis - Dataset and Transformations/actual dataset/raw_data.csv'\n",
    "    legal_data_extraction(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
