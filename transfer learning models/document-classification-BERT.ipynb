{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPvvXnf2OkWr",
    "outputId": "45522f2f-4e91-4980-84ed-a47ae2d5fcd1"
   },
   "outputs": [],
   "source": [
    "#pip install bert-tensorflow==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjwFQFSZEXb-",
    "outputId": "fa7fa81c-6894-4bd5-ce9a-f872592bd137"
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow==1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtrL0V0pMtxe"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import math\n",
    "import string\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "table = str.maketrans(dict.fromkeys(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3L8evgk-T3TH",
    "outputId": "3612a3b2-2cab-4436-8875-14e00563e4a6"
   },
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending the legal details to the summarized documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mlose-tmHZeT"
   },
   "outputs": [],
   "source": [
    "def legal_data_appending(df):\n",
    "    '''\n",
    "    Function: The legal details that were tracked using document ID between the actual data and raw data are merged in this \n",
    "    section.\n",
    "    '''\n",
    "    Summarized_Text = list()\n",
    "    for idx,row in df.iterrows():\n",
    "        Clean_Text=row['Summarized_content'].translate(table)\n",
    "        Summarized_Text.append(row['Legal_Details'] + ' ' +  Clean_Text)\n",
    "    df['Summarized_Content_LegalDetails'] = Summarized_Text\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "id": "o6agS_fmj4WM",
    "outputId": "b1756b1c-75d1-466c-988e-e822240d93f9"
   },
   "outputs": [],
   "source": [
    "# Change the path:\n",
    "# For tfidf: Thesis - Dataset and Transformations/transform - post text augmentation/lsa_tfidf_augmentation.csv\n",
    "# For tf: Thesis - Dataset and Transformations/transform - post text augmentation/lsa_tf_augmentation.csv\n",
    "df= pd.read_csv('Thesis - Dataset and Transformations/transform - post text augmentation/lsa_binary_augmentation.csv')\n",
    "df.fillna('No text',inplace=True)\n",
    "df = legal_data_appending(df)\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an output directory \n",
    "While fine-tuning the model, we will save the training checkpoints \n",
    "and the model in an output directory so that we can use the trained model for our predictions later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5ria2SgH0P4",
    "outputId": "8ca2760c-0fd5-4eca-fefa-3bc3a97fe460"
   },
   "outputs": [],
   "source": [
    " # Set the output directory for saving model file\n",
    "OUTPUT_DIR = '/content/drive/My Drive/BERT checkpoints' \n",
    "\n",
    "DO_DELETE = True #@param {type:\"boolean\"}\n",
    "\n",
    "if DO_DELETE:\n",
    "  try:\n",
    "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
    "  except:\n",
    "    pass\n",
    "\n",
    "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
    "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation and Test data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EECiwj_Molb",
    "outputId": "e9430286-6dad-4e50-b37f-ce2bad8ff347"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size = 0.2, random_state = 42)\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Training Set Shape :\", train_data.shape)\n",
    "print(\"Validation Set Shape :\", val_data.shape)\n",
    "print(\"Testing Set Shape :\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0lNQNSUqBAcq"
   },
   "outputs": [],
   "source": [
    "DATA_COLUMN_A =  'Summarized_Content_LegalDetails' \n",
    "LABEL_COLUMN = 'Labels'\n",
    "label_list = [x for x in np.unique(df.Labels)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "BERT model accept only a specific type of input and the datasets are usually structuress to have have the following four features:\n",
    "* guid : A unique id that represents an observation.\n",
    "* text_a : The text we need to classify into given categories\n",
    "* text_b: It is used when we're training a model to understand the relationship between sentences and it does not apply for classification problems.\n",
    "* label: It consists of the labels or classes or categories that a given text belongs to.\n",
    " \n",
    "In our dataset we have text_a and label. The following code block will create objects for each of the above mentioned features for all the records in our dataset using the InputExample class provided in the BERT library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pXNQsw3tXC3X"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_InputExamples = train_data.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[DATA_COLUMN_A], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "val_InputExamples = val_data.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN_A], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1CckA1WtZ6Yb",
    "outputId": "1838e83a-aa19-471e-dab2-77db49060965"
   },
   "outputs": [],
   "source": [
    "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
    "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
    "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading vocab and pretrained BERT model\n",
    "We will use the ```bert_uncased_L-12_H-768_A-12/1``` model. To check all available versions click [here](https://tfhub.dev/s?network-architecture=transformer&publisher=google).\n",
    "We will be using the vocab.txt file in the model to map the words in the dataset to indexes. Also the loaded BERT model is trained on uncased/lowercase data and hence the data we feed to train the model should also be of lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgxSfsFNYCkf",
    "outputId": "9cacfdb9-08d4-41f5-8ec1-de79f6a9aaed"
   },
   "outputs": [],
   "source": [
    "\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    with tf.Graph().as_default():\n",
    "    # Operation nodes creation.\n",
    "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "\n",
    "    return bert.tokenization.FullTokenizer(\n",
    "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting examples to features\n",
    "We will now format out text in to input features which the BERT model expects. We will also set a sequence length which will be the length of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lM93bHtDYL_d",
    "outputId": "08637db2-a61c-4233-f138-a8f5db06a5aa"
   },
   "outputs": [],
   "source": [
    "# We'll set sequences to be at most 512 tokens long.\n",
    "MAX_SEQ_LENGTH = 512\n",
    "\n",
    "# Convert our train and validation features to InputFeatures that BERT understands.\n",
    "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R9n6TTY5jaz0",
    "outputId": "09783cc5-dc8d-4093-9715-66f805aebfb6"
   },
   "outputs": [],
   "source": [
    "#Example on first observation in the training set\n",
    "i = 3509\n",
    "print(\"Sentence : \", train_InputExamples.iloc[i].text_a)\n",
    "print(\"-\"*30)\n",
    "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[i].text_a))\n",
    "print(\"-\"*30)\n",
    "print(\"Input IDs : \", train_features[i].input_ids)\n",
    "print(\"-\"*30)\n",
    "print(\"Input Masks : \", train_features[i].input_mask)\n",
    "print(\"-\"*30)\n",
    "print(\"Segment IDs : \", train_features[i].segment_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Pre-requisite understanding of create_model function** - reference from [link text](https://medium.com/@prasad.pai/how-to-use-tensorflow-hub-with-code-examples-9100edec29af)\n",
    "\n",
    "**1) Module Instantiation**: Various modules made up with different models (Inception, ResNet, ElMo etc) serving different purposes (image classification, text embeddings etc) are hosted in TensorFlow Hub website. The user has to browse through the catalogue of modules and then once finalised with his purpose and model, needs to copy the URL of the model where it is hosted. Then, the user can instantiate his module like this:\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "import tensorflow_hub as hub\n",
    "module = hub.Module(<<Module URL as string>>, trainable=True)\n",
    "```\n",
    "Apart from the URL parameter, the other most notable parameter is ‘trainable’. If user wishes to fine-tune/modify the weights of the model, this parameter has to be set as True.\n",
    "\n",
    "**2) Signature**: The signature of the module specifies what is the purpose for which module is being used for. All the module, comes with the ‘default’ signature and makes use of it, if a signature is not explicitly mentioned.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "module = hub.Module('https://tfhub.dev/google/imagenet/inception_v3/classification/1')\n",
    "print(module.get_signature_names())\n",
    "# ['default', 'image_classification', 'image_feature_vector']\n",
    "```\n",
    "**3) Expected inputs:** Each of the module has some set of expected inputs depending upon the signature of the module being used.\n",
    "\n",
    "\n",
    "```\n",
    "module = hub.Module('https://tfhub.dev/google/imagenet/inception_v3/classification/1')\n",
    "print(module.get_input_info_dict())   # When no signature is given, considers it as 'default'\n",
    "# {'images': <hub.ParsedTensorInfo shape=(?, 299, 299, 3) dtype=float32 is_sparse=False>}\n",
    "\n",
    "print(module.get_input_info_dict(signature='image_feature_vector'))\n",
    "# {'images': <hub.ParsedTensorInfo shape=(?, 299, 299, 3) dtype=float32 is_sparse=False>}\n",
    "```\n",
    "**4) Expected outputs:** In order to build the remaining part of the graph after the TensorFlow Hub’s model is built, it is necessary to know the expected type of output. get_output_info_dict() function is used for this purpose. \n",
    "\n",
    "\n",
    "```\n",
    "module = hub.Module('https://tfhub.dev/google/imagenet/inception_v3/classification/1')\n",
    "print(module.get_output_info_dict())  # When no signature is given, considers it as 'default'\n",
    "# {'default': <hub.ParsedTensorInfo shape=(?, 1001) dtype=float32 is_sparse=False>}\n",
    "\n",
    "print(module.get_output_info_dict(signature='image_classification'))\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "joAXSEi81Un4"
   },
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "\n",
    "    tags=set()\n",
    "    if not is_predicting:\n",
    "      tags.add(\"train\")\n",
    "    bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      tags = tags,\n",
    "      trainable=True)\n",
    "    bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    output_layer1 = bert_outputs[\"pooled_output\"]         \n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value   \n",
    "\n",
    "    output_weights = tf.get_variable(\n",
    "      \"output_weights\", [num_labels, hidden_size],\n",
    "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\n",
    "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)  \n",
    "    logits = tf.nn.bias_add(logits, output_bias)                        \n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)                      \n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs, output_layer1)\n",
    "\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_gk9V1SD5rc6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,num_warmup_steps):\n",
    "    '''\n",
    "    A function that adapts our model to work for training, evaluation, and prediction.\n",
    "    Model_fn_builder actually creates our model function using the passed parameters for num_labels, learning_rate, etc.\n",
    "    '''\n",
    "  \n",
    "    def model_fn(features, labels, mode, params):  \n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)         # checks if the mode == PREDICT\n",
    "\n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        acc = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        true_pos = tf.metrics.true_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        true_neg = tf.metrics.true_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)   \n",
    "        false_pos = tf.metrics.false_positives(\n",
    "            label_ids,\n",
    "            predicted_labels)  \n",
    "        false_neg = tf.metrics.false_negatives(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        recall = tf.metrics.recall(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "        precision = tf.metrics.precision(\n",
    "            label_ids,\n",
    "            predicted_labels)\n",
    "\n",
    "        return {\n",
    "            \"eval_accuracy\": acc,\n",
    "            \"true_positives\": true_pos,\n",
    "            \"true_negatives\": true_neg,\n",
    "            \"false_positives\": false_pos,\n",
    "            \"false_negatives\": false_neg,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      # For mode == ModeKeys.TRAIN: required fields are loss and train_op.\n",
    "      # For mode == ModeKeys.EVAL: required field is loss.\n",
    "      # For mode == ModeKeys.PREDICT: required fields are predictions.\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:                 \n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,            \n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:                                                          \n",
    "      (predicted_labels, log_probs, output_layer) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels,\n",
    "          'pooled_output': output_layer\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions) # The dictionary for the predictions is created above.\n",
    "\n",
    "    # Return the actual model function in the closure\n",
    "    return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IbJv8FqsxYsf"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8                                        \n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 3.0\n",
    "WARMUP_PROPORTION = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GpIqmM68xl_D",
    "outputId": "4b1ce81e-1483-4f55-9b6c-a1790f443c09"
   },
   "outputs": [],
   "source": [
    "#Compute train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "print('The number of train steps', num_train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZHd2mLQxoAP"
   },
   "outputs": [],
   "source": [
    "SAVE_CHECKPOINTS_STEPS = 600\n",
    "SAVE_SUMMARY_STEPS = 600\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FXrOBCItxqXF",
    "outputId": "45008c48-74e4-4b3d-bd10-ad24a0f82a18"
   },
   "outputs": [],
   "source": [
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gWJWkp7yydNn"
   },
   "outputs": [],
   "source": [
    "train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "    features=train_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=True,\n",
    "    drop_remainder=False)\n",
    "\n",
    "val_input_fn = run_classifier.input_fn_builder(\n",
    "    features=val_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5oUY4rYsyhbc",
    "outputId": "daa2db46-124e-4b71-ec7a-728641f3cf1c"
   },
   "outputs": [],
   "source": [
    "print(f'Beginning Training!')\n",
    "current_time = datetime.now()\n",
    "train_estimator = estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "print(\"Training took time \", datetime.now() - current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LarVvyV5yh7K",
    "outputId": "6c61b5d1-47b7-42a4-c8bd-d09dc92e2c28"
   },
   "outputs": [],
   "source": [
    "#Evaluating the model with Validation set\n",
    "validation_estimator = estimator.evaluate(input_fn=val_input_fn, steps=None)\n",
    "\n",
    "#If you want to consider evaluation from a specific checkpoint then add this parameter to the estimator:\n",
    "#checkpoint_path='/content/drive/My Drive/BERT checkpoints/model.ckpt-6000')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nPqQNDDDqfH"
   },
   "source": [
    "## Performance on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QPyo4KBRDqfI"
   },
   "outputs": [],
   "source": [
    "def getPrediction(in_sentences):\n",
    "  #Transforming the test data into BERT accepted form\n",
    "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
    "  \n",
    "  #Creating input features for Test data\n",
    "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "  #Predicting the classes \n",
    "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "  predictions = estimator.predict(predict_input_fn, yield_single_examples=True)\n",
    "  return [(sentence, prediction['probabilities'],prediction['labels']) for sentence, prediction in zip(in_sentences, predictions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aes8RUQsDqfI",
    "outputId": "f08925f9-6a32-4463-9fd8-2272499402a6"
   },
   "outputs": [],
   "source": [
    "#predictions = getPrediction(pred_sentences_A, pred_sentences_B)\n",
    "pred_sentences = list(test_data[DATA_COLUMN_A])\n",
    "predictions = getPrediction(pred_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtONWnXiDqfI"
   },
   "outputs": [],
   "source": [
    "predict_labels = []\n",
    "act_labels = []\n",
    "for i in range(len(predictions)):\n",
    "  predict_labels.append(predictions[i][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ki-jwB24DqfI",
    "outputId": "f7239af8-1ba3-444d-c9eb-330d0b7af835"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(list(test_data['Labels']), predict_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6lPKwc7DqfI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def heatconmat(y_true,y_pred):\n",
    "    sns.set_context('talk')\n",
    "    plt.figure(figsize=(15,12))\n",
    "    sns.heatmap(confusion_matrix(y_true,y_pred),\n",
    "                annot=True,\n",
    "                fmt='d',\n",
    "                cbar=False,\n",
    "                cmap='gist_earth_r',\n",
    "                yticklabels=sorted(y_true.unique()))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "id": "AxbPzxobDqfJ",
    "outputId": "942a8a91-47b7-4ebb-ca41-5eeb5ad64dfe"
   },
   "outputs": [],
   "source": [
    "heatconmat(test_data['Labels'],predict_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hAj8bLaZSmBB"
   },
   "source": [
    "### **Intermediate results with parameter details to decide the threshold Sigma value for SVD by fine tuning on a dataset with documents from 5 labels:**\n",
    "\n",
    "\n",
    "**1.** Thresh_sigma = 0.5\n",
    "\n",
    "\n",
    "\n",
    "BERT Evaluation results:\n",
    "* 'Precision': 0.9358491,\n",
    "* 'Recall': 0.95384616,\n",
    "* 'eval_accuracy': 0.8985849,\n",
    "* 'false_negatives': 12.0,\n",
    "* 'false_positives': 17.0,\n",
    "* 'global_step': 636,\n",
    "* 'loss': 0.35691655,\n",
    "* 'true_negatives': 147.0,\n",
    "* 'true_positives': 248.0.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "**2.** Thresh_sigma = 0.6\n",
    "\n",
    "\n",
    "BERT Evaluation results:\n",
    "* 'Precision': 0.9266409,\n",
    "* 'Recall': 0.9230769,\n",
    "* 'eval_accuracy': 0.8419811,\n",
    "* 'false_negatives': 20.0,\n",
    "* 'false_positives': 19.0,\n",
    "* 'global_step': 636,\n",
    "* 'loss': 0.50120294,\n",
    "* 'true_negatives': 145.0,\n",
    "* 'true_positives': 240.0.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "**3.** Thresh_sigma = 0.7\n",
    "\n",
    "\n",
    "\n",
    "BERT Evaluation results:\n",
    "* 'Precision': 0.9348659,\n",
    "* 'Recall': 0.93846154,\n",
    "* 'eval_accuracy': 0.8962264,\n",
    "* 'false_negatives': 16.0,\n",
    "* 'false_positives': 17.0,\n",
    "* 'global_step': 600,\n",
    "* 'loss': 0.3652602,\n",
    "* 'true_negatives': 147.0,\n",
    "* 'true_positives': 244.0.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "**4.** Thresh_sigma = 0.8\n",
    "\n",
    "\n",
    "\n",
    "BERT Evaluation results:\n",
    "* 'Precision': 0.9455253,\n",
    "* 'Recall': 0.9346154,\n",
    "* 'eval_accuracy': 0.8985849,\n",
    "* 'false_negatives': 17.0,\n",
    "* 'false_positives': 14.0,\n",
    "* 'global_step': 636,\n",
    "* 'loss': 0.3684816,\n",
    "* 'true_negatives': 150.0,\n",
    "* 'true_positives': 243.0\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "**5.** Thresh_sigma = 0.9\n",
    "\n",
    "\n",
    "\n",
    "BERT Evaluation results:\n",
    "* 'Precision': 0.9157509,\n",
    "* 'Recall': 0.96153843,\n",
    "* 'eval_accuracy': 0.8773585,\n",
    "* 'false_negatives': 10.0,\n",
    "* 'false_positives': 23.0,\n",
    "* 'global_step': 600,\n",
    "* 'loss': 0.41267064,\n",
    "* 'true_negatives': 141.0,\n",
    "* 'true_positives': 250.0\n",
    "\n",
    "-------------------------------------------------------------------------------------------------\n",
    "**6.** Thresh_sigma = 1.0\n",
    "\n",
    "\n",
    "\n",
    "BERT Evaluation results:\n",
    "* Precision: 0.93846154,\n",
    "* Recall: 0.93846154,\n",
    "* eval_accuracy: 0.8915094,\n",
    "* false_negatives: 16.0,\n",
    "* false_positives: 16.0,\n",
    "* global_step: 600,\n",
    "* loss: 0.38839507,\n",
    "* true_negatives: 148.0,\n",
    "* true_positives: 244.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "phase - BERT document classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
